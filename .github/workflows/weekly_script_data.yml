name: Weekly Data Scraping and Storage

on:
  schedule:
    - cron: "0 0 * * 0"  # Run every Sunday at midnight UTC
  workflow_dispatch:  # Enable manual triggering
    inputs:
      message:
        description: 'Run on manual triggering'
        required: false

jobs:
  scrape_and_store_data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10.11'  # Specify the Python version

      - name: Check GPU
        run: lspci | grep -i nvidia
      
      - name: Check GCC Version
        run: gcc --version
      
      - name: Download NVIDIA CUDA Repository Key
        run: |
          curl -O https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub
          sudo mv 7fa2af80.pub /usr/share/keyrings/
      
      - name: Add CUDA Repository
        run: |
          echo "deb [signed-by=/usr/share/keyrings/7fa2af80.pub] https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 /" | sudo tee /etc/apt/sources.list.d/cuda.list
          sudo apt-get update
      
      - name: Verify CUDA Availability
        run: sudo apt-cache policy cuda
      
      - name: Install CUDA Toolkit
        run: sudo apt-get install -y cuda
      
      - name: Verify CUDA Installation
        run: nvcc --version  # Check CUDA compiler version

      - name: Add NVIDIA CUDA repository key
        run: |
          curl -O https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub
          sudo mv 7fa2af80.pub /usr/share/keyrings/

      - name: Add NVIDIA CUDA repository
        run: |
          echo "deb [signed-by=/usr/share/keyrings/7fa2af80.pub] https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 /" | sudo tee /etc/apt/sources.list.d/cuda.list
          sudo apt-get update

      - name: Install CUDA Toolkit
        run: |
          sudo apt-get install -y cuda

      - name: Install System Dependencies
        run: |
          sudo apt-get install -y cmake swig build-essential

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade tensorflow keras
          pip install --no-deps --no-cache-dir -r requirements.txt  # Install project dependencies

      - name: Install Azure CLI
        uses: azure/CLI@v1
        with:
          inlineScript: |
            # Your Azure CLI commands go here
            az --version

      - name: Execute data scraping script
        env:
          DATA_FOLDER: ${{ github.workspace }}/src/data
        run: python src/data_scraping.py

      - name: Upload data to Azure Blob Storage
        run: |
          az storage blob upload \
            --connection-string "${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}" \
            --container-name stock-prediction-data \
            --file src/data/StockPriceDataWebScraped.parquet  # Corrected file path
            --name StockPriceData.parquet \
            --overwrite