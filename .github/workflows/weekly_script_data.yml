name: Weekly Data Scraping and Storage

on:
  schedule:
    - cron: "0 0 * * 0"  # Run every Sunday at midnight UTC
  workflow_dispatch:  # Enable manual triggering
    inputs:
      message:
        description: 'Run on manual triggering'
        required: false

jobs:
  scrape_and_store_data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10.11'  # Specify the Python version

      - name: Install CUDA Toolkit
        run: |
          wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
          sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
          sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub
          sudo add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /"
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends cuda-toolkit-11-4

      - name: Set CUDA Environment Variables
        run: |
          echo 'export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}' >> $HOME/.bashrc
          echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}' >> $HOME/.bashrc
          source $HOME/.bashrc

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade tensorflow keras
          pip install --no-deps --no-cache-dir -r requirements.txt  # Install project dependencies

      - name: Install Azure CLI
        uses: azure/CLI@v1
        with:
          inlineScript: |
            # Your Azure CLI commands go here
            az --version

      - name: Execute data scraping script
        env:
          DATA_FOLDER: ${{ github.workspace }}/src/data
        run: python src/data_scraping.py

      - name: Upload data to Azure Blob Storage
        run: |
          az storage blob upload \
            --connection-string "${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}" \
            --container-name stock-prediction-data \
            --file src/data/StockPriceDataWebScraped.parquet  # Corrected file path
            --name StockPriceData.parquet \
            --overwrite
