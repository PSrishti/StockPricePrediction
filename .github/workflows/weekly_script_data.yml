name: Weekly Data Scraping and Storage

on:
  schedule:
    - cron: "0 0 * * 0"  # Run every Sunday at midnight UTC (adjust as needed)

jobs:
  scrape_and_store_data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10.11'  # Specify the Python version

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade tensorflow keras
          pip install --no-deps --no-cache-dir -r requirements.txt  # Install project dependencies

      - name: Install Azure CLI
        uses: azure/setup-azure-cli@v1

      - name: Execute data scraping script
        env:
          DATA_FOLDER: ${{ github.workspace }}/src/data
        run: python /Users/srishtipandey/Desktop/StockPricePrediction/src/data_scraping.py

      - name: Upload data to Azure Blob Storage
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: |
          az storage blob upload \
            --container-name stock-prediction-data \
            --file /src/data/StockPriceDataWebScraped.parquet \
            --name StockPriceData.parquet \
            --overwrite
